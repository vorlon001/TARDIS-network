https://dzen.ru/a/ZMJRLt5EpgbeE5mL

Свойства Kafka
--------------

1.  Распределенность;
2.  Отказоустойчивость;
3.  Горизонтальное масштабирование;
4.  Высокая доступность;
5.  Надёжность и согласованность данных;
6.  Высокая производительность;
7.  Интегрируемость.

Решаемые задачи
---------------

Предположим, что у нас есть несколько однотипных или разнородных событий или сообщений, которые необходимо передать. При этом у нас есть поставщики данных и есть получатели данных. При этом разным потребителям нужны разные данные. Реализация довольна трудоёмкая, возникают следующие сложности, а именно

*   Надежность и гарантия доставки данных (продюсеры должны все знать о консьюмерах);
*   Подключение новых получателей;
*   Интеграция новых стеков;
*   Техническая поддержка.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-2](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c252e36f5c4c6c604cc262)

Стандартное решение — посредник (брокер), который примет на себя задачу получения данных и их выдачу.

Гарантию надежности обеспечивает брокер, интеграция стеков происходит просто, продюсерам и консьюмерам нужно знать только API брокера, между собой они не общаются.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-3](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES///pub_64c2512ede44a606de13998b_64c2532f16c88734fd6b27b3)

Основные сущности
-----------------

Структура Kafka состоит из нескольких компонентов:

*   **Kafka Node** – это сервер в распределенной системе Kafka, который обрабатывает данные и предоставляет их по запросу;
*   **Topic** – это место, где сообщения хранятся в Kafka. Это может быть любая валидная строка UTF-8 символов;
*   **Partition** – это раздел топика, который используется для распределения сообщений между серверами в кластере Kafka;
*   **Producer** – это приложение, которое отправляет сообщения в топик;
*   **Consumer** – это приложение, которое получает сообщения из топика.

Kafka Broker (Kafka Server | Kafka Node)
----------------------------------------

**Apache Kafka Broker** - это сервер, который предоставляет хранилище и обрабатывает потоки данных (_streams_) в Apache Kafka. **Broker** отвечает за хранение и обработку сообщений, которые были опубликованы в топик (_topic_) производителями (_producers_), а также за отправку этих сообщений подписчикам (_consumers_).

Брокеры в Kafka представляют собой кластер серверов, которые могут быть запущены на различных узлах сети. Система репликации позволяет обеспечить отказоустойчивость и терпимость к отказам путем хранения нескольких реплик топика на разных брокерах. Если один из брокеров выходит из строя, Kafka автоматически переназначает реплики на другие брокеры и устанавливает новое соединение между ними.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-4](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c253ee282eb424ab4064f8)

Каждый брокер в Kafka имеет свой уникальный идентификатор (**Broker ID**) и хранит множество топиков, которые он обрабатывает. Топики в Kafka разбиваются на партиции (partitions), каждая из которых может распределяться между несколькими брокерами.

**Apache Kafka Broker** обеспечивает также возможность обработки потоков данных (_streams_) в режиме реального времени. Это достигается путем использования архитектуры, основанной на концепции **publish-subscribe**. Производители (_producers_) публикуют данные в топик, а подписчики (_consumers_) получают эти данные. В Kafka есть возможность создания нескольких потоков обработки данных (_stream processing_), которые могут быть сконфигурированы для обработки данных в реальном времени.

Кроме того, **Apache Kafka Broker** имеет богатый набор API для управления топиками и конфигурациями брокеров. Брокеры поддерживают управление авторизацией и аутентификацией, аудитом и мониторингом, а также масштабируются горизонтально и вертикально, чтобы обеспечить обработку больших объемов данных.

Среди брокеров выделяется **Kafka Controller**, который отвечает за консистентность данных, так как Kafka является _Master-slave_ системой. За выбор контроллера отвечает **Zookeeper**.

Zookeeper
---------

**Zookeeper** - это координирующий сервис, который используется в Apache Kafka для управления конфигурацией и обеспечения оркестрации между брокерами и потребителями.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-5](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c25503b3fcce7e95d6d440)

В Apache Kafka, **Zookeeper** выполняет следующие задачи:

1.  Хранение метаданных: **Zookeeper** хранит метаданные, связанные с Kafka, включая информацию о кластере, топиках, партициях, брокерах и потребителях.
2.  Управление репликацией: **Zookeeper** отвечает за управление репликацией данных в Kafka при помощи **Replica Manager**, который отслеживает состояние реплик и координирует переназначение реплик в случае отказов.
3.  Координация потребителей: Потребители Kafka используют **Zookeeper** для координации своей работы внутри потребительской группы. **Zookeeper** управляет процессом распределения партиций между потребителями и отслеживает текущее состояние работающих потребителей в группе.
4.  Управление сессиями: **Zookeeper** отслеживает активность брокеров, потребителей и других участников кластера Kafka и управляет их сессиями. Если участник не отвечает, **Zookeeper** удаляет его из списка активных участников.
5.  Управление конфигурацией: **Zookeeper** отвечает за хранение конфигурации Kafka и управление приоритетом брокеров в кластере.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-6](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES///pub_64c2512ede44a606de13998b_64c2557ebde89b3460733636)

Таким образом, **Zookeeper** в Apache Kafka используется для управления конфигурацией и обеспечения оркестрации между брокерами, потребителями и другими участниками кластера. Он позволяет обеспечить высокую отказоустойчивость и эффективную работу Kafka в условиях широкомасштабной разработки и эксплуатации.

**Сообщение (message)**
-----------------------

**Сообщение (message)** в Apache Kafka представляет собой небольшой объем данных, который может быть отправлен и получен с помощью **Producer** и **Consumer**.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-7](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c25630de44a606de1c3c78)

Каждое сообщение в Kafka снабжено ключом (_key_), значением (_value_) и метаданными (_metadata_), которые включают топик (_topic_), партицию (_partition_) и смещение (_offset_) в партиции, на которую было записано сообщение.

Ключ сообщения используется для определения партиции, на которую будет записано сообщение. В идеале, ключ должен быть уникальным для каждого сообщения, чтобы гарантировать, что оно будет записано на одну и ту же партицию и избежать перезаписи или потери данных. Если ключ не указан, или он не позволяет определить партицию, используется случайный выбор из доступных партиций.

Значение сообщения содержит сами данные, которые необходимо передать.

Метаданные сообщения включают информацию о топике, партиции и оффсете в партиции, на которую было записано сообщение. Оффсеты используются для уникальной идентификации сообщений в топике и партиции и обеспечивают возможность безопасного чтения сообщений с помощью **Consumer**.

Kafka Topic
-----------

**Топик (Topic)** в Apache Kafka представляет собой логически независимый канал, который используется для организации и хранения сообщений.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-8](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES///pub_64c2512ede44a606de13998b_64c25667c146cc22fbb399db)

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-9](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c260b66f5c4c6c60648414)

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-10](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c2610db03b7c165e267ee9)

Каждый топик в Kafka представляет собой логически разделяемый поток сообщений, который может быть записан или прочитан с помощью **Producer** или **Consumer**.

Топики обычно связываются с конкретными категориями данных, такими как отчеты, логи, события и т.д. Для каждого топика определяется имя и несколько партиций.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-11](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c26123282eb424ab57114c)

**Партиция (Partition)** в Kafka является физической единицей хранения данных. Каждый топик может содержать несколько партиций, которые распределяются между участниками кластера Kafka и используются для балансировки нагрузки, обеспечения отказоустойчивости и распределения чтения сообщений.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-12](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c26134b03b7c165e26d10e)

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-13](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c2614c69d16c67033203cf)

Каждая партиция состоит из набора сегментов (_segment_), которые содержат сообщения в логическом порядке и сохраняются на диске. При записи новых сообщений сегменты растут по мере необходимости, а старые сегменты могут быть удалены в зависимости от настроек хранения и управления пространством.

Файловая система брокера
------------------------

Данные хранятся в **Log-файлах**. Если посмотреть на файловую систему брокера, в папку _logs_, мы увидим в ней папки под каждую партицию, их имя состоит из имени топика и номера партиции через дефис.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-14](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c261e25e5c747862cbd583)

Внутри мы увидим 3 файла - **.log, .index** и **.timeindex**.

*   **.log** — файл содержит данные которые мы отправляем, с доп информацией _timestamp, offset, position_ (смещение по файлу на базе _offset_)
*   **.index** - хранит в себе данные об _offset_ и _position_.
*   **.timeindex** — хранит в себе _timestamp_ и _offset._ За основу _timestamp_ берется системное время.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-15](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c261f816c88734fd8499a2)

Если топик поработает больше, то мы увидим ещё 3 файла, но с другим именем. **Log** файл залимитирован на 1 Гб. Если лимит превышается , то файл закрывается и создается новый в имени которого будет содержаться _offset_ на котором была приостановлена запись. Будет создан новый _segment_.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-16](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c2620fbde89b34608bfd6d)

Операция удаления данных не поддерживается, но есть автоматическое удаление по **TTL (time-to-live)**, при привышении установленного _timestamp_ будет удален сегмент целиком, а не только определенное сообщение. Возможна ситуация, когда _timestamp_ будет установлен в будущее, тогда удаление по **TTL** не будет произведено.

### Репликации

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-17](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c26319cef63a68ef17ebbb)

**Replication-factor** - специальная настройка которая позволяет создавать реплики партиций на других брокерах. При использовании репликации есть возможность отставания данных.

Одна из реплики назначается **Leader-репликой**, остальные _followers_. За назначение **Leader-реплик** отвечает _Kafka Controller._ Чтение и запись производится только с **Leader-реплик**.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-18](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c2628540a38d7707b64d0f)

Когда в лидер-реплику попадают данные, **followers** опрашивают лидера по **pull** протоколу на наличие новых данных. Если лидер упадет может произойти утеря данных. Для решения проблемы есть функция **in-sync replicas (ISR)**. При её использовании происходит синхронная запись и в лидер и в **isr-follower** и если упадет лидер реплика **isr-replica** будет лучшим кандидатом на лидер реплику.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-19](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c262a3228faa138462eaee)

Kafka Producer
--------------

**Kafka Producer** - это компонент Apache Kafka, который отвечает за отправку сообщений (или записей) в Kafka топики. **Producer** может отправлять данные в один или несколько топиков, группируя их в пакеты для более эффективной передачи.  
  
Основные задачи **Kafka Producer** включают:  
  
1\. Сообщение: **Producer** принимает входные данные и преобразует их в сообщения Kafka.  
2\. Партиционирование: **Producer** может указать, в какую партицию или несколько партиций отправить сообщение. Это позволяет контролировать распределение данных по разным партициям и обеспечить балансировку нагрузки.  
3\. Сериализация: **Producer** сериализует сообщения в нужный формат перед отправкой в Kafka, чтобы они могли быть правильно интерпретированы и обработаны потребителями.  
4\. Отправка: **Producer** отправляет сообщения на Kafka брокеры для обработки и хранения.  
5\. Упорядочивание: **Producer** может гарантировать порядок доставки сообщений внутри определенной партиции путем указания ключа сообщения.  
6\. Масштабируемость: **Producer** может горизонтально масштабироваться путем добавления новых экземпляров для обработки больших объемов данных.**Kafka Producer** обеспечивает надежную и масштабируемую передачу данных в Kafka топики, что делает его одним из основных компонентов в экосистеме Apache Kafka.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-20](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c263f4de44a606de33dc79)

### Kafka Producer. Функция send message

Функция **send message** в **Kafka Producer** отправляет одно или несколько сообщений в Kafka-топик. Она принимает сообщение в виде ключа и значения, и может также принимать дополнительные параметры и метаданные. **Send message** выполняет действия по сетевому взаимодействию для отправки сообщения в Kafka-топик, включая сериализацию данных, разделение сообщений по партициям и передачу данных брокеру Kafka.

### Kafka Producer. Функция fetch metadata

Функция **fetch metadata** в **Kafka Producer** выполняет запрос метаданных к брокеру Kafka. Метаданные включают информацию о топиках, партициях и брокерах, которые участвуют в обмене сообщениями.  
  
Эта функция используется для получения актуальной информации о разделении данных и распределении в брокерах. Когда **Kafka Producer** отправляет сообщение, он использует метаданные для определения, куда отправить сообщение, в какую топику и партицию.**Fetch metadata** позволяет производителю быть в курсе изменений в топиках и партициях в реальном времени и корректно обрабатывать отправку сообщений.

### Kafka Producer. Функция serialize message

Функция **serialize message** в **Kafka Producer** выполняет сериализацию (преобразование) сообщения в бинарный формат перед отправкой его в Kafka-топик. Это необходимо, так как Kafka работает с бинарными данными.  
  
После сериализации, бинарное представление сообщения передается **Kafka Producer**, который затем отправляет его в Kafka-топик для дальнейшей обработки и потребления.

### Kafka Producer. Функция define partition

Функция **define partition** в **Kafka Producer** определяет, на какую партицию будет отправлено каждое сообщение.  
Определение партиции для каждого сообщения имеет две цели:  
  
1\. Гарантировать упорядоченность: Каждая партиция в Kafka имеет определенный порядок записи, и сообщения отправляются в этом порядке. Если производитель выбирает партицию для каждого сообщения, он может контролировать порядок, в котором они будут обработаны.  
  
2\. Распределение нагрузки: Разбиение данных на несколько партиций позволяет распределить нагрузку между различными брокерами Kafka. Каждый брокер может обрабатывать записи только из определенных партиций, что позволяет более эффективно использовать вычислительные ресурсы.  
  
Функция **define partition** позволяет производителю указать на конкретную партицию, либо использовать дефолтное поведение Kafka, которое основывается на ключе сообщения. При использовании дефолтного поведения Kafka будет использовать хэш-код ключа для определения на какую партицию будет отправлено сообщение.

### Kafka Producer. Функция compress message

Функция **compress message** в **Kafka Producer** сжимает сообщение перед его отправкой на брокер Kafka. Сжатие сообщений позволяет уменьшить размер сообщений и, следовательно, уменьшить потребление сетевого трафика при передаче сообщений.  
  
В Kafka доступны различные алгоритмы сжатия, такие как _GZIP, Snappy_ и _LZ4_. Каждый из алгоритмов имеет свои преимущества и недостатки в отношении сжатия и производительности. При выборе алгоритма сжатия необходимо учитывать подходящие требования по объему сжатия и требования по производительности.  
  
Функция **compress message** в **Kafka Producer** принимает на вход сообщение и применяет алгоритм сжатия, указанный в настройках **Kafka Producer**. Затем сжатое сообщение отправляется на брокер Kafka для дальнейшей обработки и сохранения.

### Kafka Producer. Функция accumulate batch

Функция **accumulate batch** в **Kafka Producer** позволяет накапливать и объединять несколько сообщений в одну пачку перед отправкой в брокер Kafka.  
  
Когда производитель Kafka получает новые сообщения, он может собирать их в пачки (_batch_) вместо отправки каждого сообщения независимо. Пачка содержит несколько записей, которые будут переданы в брокер Kafka вместе.  
  
**Accumulate batch** позволяет производителю накапливать и объединять сообщения в пачки, чтобы уменьшить накладные расходы на сеть и повысить производительность. После достижения определенного количества сообщений или интервала времени, накопленная пачка будет отправлена.  
  
Функция **accumulate batch** также может выполнять компрессию сообщений, чтобы уменьшить размер пачки перед отправкой и снизить использование сетевых ресурсов. Компрессия может быть включена и настроена для различных алгоритмов сжатия, таких как _gzip_ или _snappy_.  
  
В целом, функция **accumulate batch** позволяет эффективно использовать ресурсы и уменьшить задержку при передаче сообщений в Kafka брокер.

### Kafka Consumer

**Kafka Consumer** - это клиент, который используется для чтения данных из **Apache Kafka-топиков**. Он подписывается на один или несколько топиков и получает сообщения, опубликованные в этих топиках. Клиент _Kafka Consumer_ работает по модели **pull**, то есть сам решает, когда и какие сообщения читать из топиков. Консьюмеры могут быть разделены на группы, и каждая группа будет читать сообщения из разных частей топика для обеспечения распределенного чтения и параллельной обработки данных. Они обрабатывают данные в реальном времени и могут использоваться для различных целей, таких как аналитика, потребление данных, обработка событий и т.д.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-21](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c26bab558bf2028b0cca5d)

Функция **poll messages** в **Kafka Consumer** выполняет следующие действия:  
  
1\. Отправляет запрос на брокеру Kafka для получения новых сообщений из одной или нескольких тем.  
2\. Получает сообщения в виде набора записей (_Records_).  
3\. Обрабатывает каждую запись и выполнение нужной логики, например, сохранение сообщения в базу данных, обработка и анализ данных и т.д.  
4\. Подтверждает, что сообщения были успешно получены и обработаны.  
5\. При необходимости, можно также выполнить коммит оффсетов _(offset commit)_ для сохранения информации о последней успешной обработке сообщений.  
  
Функция **poll messages** является блокирующей, то есть, если новые сообщения еще не доступны в брокере, функция будет ожидать их появления.

Функция **fetch metadata** в **Kafka Consumer** отправляет запрос на метаданные брокеров Kafka и топиков, чтобы получить информацию о разделах (_partitions_), брокерах и лидерах разделов. Это позволяет получить информацию о том, какие топики и разделы доступны для чтения и к каким брокерам нужно подключиться для чтения сообщений в этих разделах. Когда **Kafka Consumer** запрашивает метаданные, он получает ответ от брокера Kafka со списком топиков и их разделов, а также информацию о брокерах, лидерах разделов и их смещениях (_offsets_). Затем **Kafka Consumer** может использовать эту информацию для установления соединения с нужными брокерами и чтения сообщений из соответствующих разделов.

Далее идет потребление данных из партиций, если только один _consumer_ то он читает сразу из всех лидер-партиций. Это не всегда производительно. Мы можем запустить несколько консьюмеров указав им _group.id_ тем самым объединив их в группу. Создавать консьюмеров больше чем есть лидер партиций нецелесообразно, так как один будет простаивать.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-22](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES///pub_64c2512ede44a606de13998b_64c26c433fc50007bd74d27a)

### Kafka Consumer Offset

**Оффсет (Offset)** в Apache Kafka является уникальным идентификатором конкретного сообщения внутри партиции топика.

Каждое сообщение, отправленное на Kafka, получает свой собственный оффсет, который определяет его позицию в рамках партиции. Оффсеты нумеруются от начала каждой партиции и увеличиваются с каждым новым сообщением в порядке их добавления в партицию.

Оффсеты используются в Kafka для управления чтением и записью сообщений консьюмерами и продюсерами. Консьюмеры используют оффсеты для учета того, какие сообщения уже были прочитаны, и для продолжения чтения сообщений с определенной позиции в партиции. Продюсеры, с другой стороны, используют оффсеты для контроля того, какие сообщения уже были отправлены на Kafka.

Оффсеты также обеспечивают безопасность сообщений в Kafka, позволяя консьюмерам безопасно читать сообщения из партиции, даже если несколько консьюмеров одновременно читают сообщения из этой партиции.

Для хранения коммитов на брокер создается отдельный топик - _\_\_consumer\_offsets._

В нем храняться оффсеты для каждой партиции, внутри храняться данные о партиции группе и оффсете.

Если вдруг при обработки первых трех сообщений из пяти консьюмер падает, то рабочий консьюмер запрашивает из системного топика нформацию о партиции , о конечном положении обработанных сообщений и чтение продолжается с 4 сообщения.

Есть несколько видов коммитов

*   **Auto-commit** — при получении консьюмером сообщения, позиция сразу закоммичивается, но если консьюмер упал, не успев обработать сообщение, второй рабочий консьюмер начнет запрос с закоммиченой позиции тем самым возможна потеря сообщений.
*   **Manual-commit** — ручной коммит, может быть дубликация сообщений.
*   **Custom offset managment** — собственное хранилище оффсетов, при использовании данного способа, мы не используем встроенный топик для хранения оффсетов. Сложный в реализации механизм.

![История создания Apache Kafka была разработана Джейем Креймеером, Неха Наркаром и Мартьяном Клянкой, которые работали в LinkedIn.-23](https://raw.githubusercontent.com/vorlon001/TARDIS-network/main/IMAGES//pub_64c2512ede44a606de13998b_64c26f41684a440e776ec2bc)

**Оффсет может пропасть для консьюмер группы**

*   Максимальный период бездействия:

_offsets.retention.minutes_ (7 дней дефолт) если консьюмер группа не работала установленное время - оффсеты будут удалены.

*   После того, как группа снова активна:

_auto.offset.reset — earliest | latest_. Либо с первого доступного сообщения, либо с последнего (новые сообщения).

На этом всё! Если у вас есть вопросы или требуется помощь - мы всегда рады помочь!
